\documentclass[runningheads,a4paper]{llncs}

\usepackage{graphicx}
\usepackage{subfigure}
\usepackage[strings]{underscore}

\title{Comparison of explanations of simple and complex ML models}

\titlerunning{Comparison of explanations of simple and complex ML models}

\author{Ruiyu Wang}

\institute{MSc in Advanced Computer Science, \\ School of Computing Science,
        University of Newcastle, U. K. \\
        \email{r.wang57@ncl.ac.uk}
}
\begin{document}

\maketitle

\section{Introduction}

With the success of machine learning (ML) in more and more areas in recent years, the need for explainability of ML has grown.

ML is now widely used in many domains, such as alphaGO and ChatGPT.
However, ML models often fail to explain their predictions. For example,  in alphaGO, the model will only give a way to win the game, but it will not explain why that way wins.
Why this method wins. In some specific domains, the loss of explanation is often accompanied by a loss of trust.
There is also a loss of trust. 
For example, in medicine, if the model just gives a diagnosis without any explanation, it often fails to gain trust. This is because the cost of models that make incorrect predictions is often prohibitive.

Model interpretation in ML is the process of interpreting the behaviour and results of ML models \cite{doshivelez2017rigorous}.
A good explanation intuitively gives the reason why the model makes the predictions it does.
This process can make the black box prediction process transparent.\cite{8466590}
The trustability and transparency of the model is ensured through the interpretation of the model\cite{arrieta2020explainable}\cite{Molnar2020}, which strengthens the user's trust in the model's prediction results.
At the same time, the interpretation of the model can often be used to improve the model or to gain some knowledge through the model.\cite{8466590}

The complexity of generating explanations is directly proportional to the complexity of the ML algorithm that generates the model.
Explaining the simplest linear regression can be done with simple arithmetic. Explaining complex deep neural networks is frequently, nevertheless, difficult to begin with.
As a result, many model-agnostic interpretation methods have been proposed and widely used.
SHAP (SHapley Additive exPlanations)\cite{lundberg2017unified} is one of the most representative methods.

At the same time, noise in datasets is one of the problems often faced in the field of ML.
Datasets in nature are often not perfect, and noise can come from many sources, including incorrect collection by humans or instruments.
Data with noise often negatively affects the prediction results of machine learning models \cite{GUPTA2019466}\cite{saseendran2019impact}.

The aim of this paper is to generate and compare interpretations of simple or complex ML models on synthetic datasets containing different levels of noise.

Section 2 gives a brief history of the development of machine learning interpretation techniques. 
Section 3 describes the experimental setup and datasets generation method. 
Section 4 will describe some of the methods used in the experiments, such as HalvingGridSearchCV and nested cross-validation.
Section 5 and Section 6 describe the experimental procedure and analyse the results. 
Finally, Section 7 summarises the results of the experiments and gives conclusions about the comparison experiments.

\section{Background of Interpretation}

Interpretation methods for ML models can usually be categorised into two types: model-specific or model-agnostic interpretation methods\cite{doshivelez2017rigorous}.

\subsection{Model-specific Interpretation}

For simple models (e.g. linear regression, logistic regression, decision trees, etc.), assumptions about the distribution  are often made in advance\cite{doshivelez2017rigorous}.
These assumptions lead to a simpler structure of the models, making them easier to interpret.
For example, Before using linear regression, the user needs to first assume that the predictions are linear.
Linear regression generates predictions by linearly combining the features.
Gauss has been using linear regression since the nineteenth century\cite{gauss1877theoria},this is precisely because the principle of linear regression is very simple: find a line in space such that the sum of the distances from each data point to the line is the shortest.


However, model-specific interpretation methods tend to apply only to simple models. The internals of highly complex models are not analysed and interpreted.

\subsection{Model-agnostic Interpretation}
Many model agnostic approaches have been proposed in recent years. 
These methods involve interpreting the model after training.
Among them, the most representative are LIME and SHAP.
SHAP is used in this paper because it is an improvement of LIME with better functionality\cite{alvarezmelis2018robustness}.
\subsubsection{LIME}
In 2016, LIME was proposed by Ribeiro et al\cite{ribeiro2016should}.
LIME is interpreted by inputting individual data points into the model to capture individual predictions. Perturbation data is then input to capture changes in the predictions to generate an interpretation of the model.
\subsubsection{SHAP}
Lundberg and Lee presented SHAP in 2017\cite{lundberg2017unified}.
SHAP is based on the Shapley value in game theory \cite{Shapley1953}, a method of allocating profits according to contributions.
SHAP can decompose a prediction into the contributions made to the prediction by each feature of the input data.
While highlighting the contribution of individual features, SHAP also indicates the impact of interactions between features on the prediction \cite{lundberg2017unified}.
In other words, the biggest difference between SHAP and LIME is that SHAP introduces the Shapley value to calculate the contribution made by features to the prediction\cite{lundberg2017unified}.
From 2017 to the present, SHAP has undergone many updates, including the launch of TreeSHAP in 2019\cite{lundberg2019consistent}.
This is the SHAP variant for tree-based machine learning models such as decision trees, random forests and gradient boosting trees. 
Compared to the original KernelSHAP, TreeSHAP is faster, but somewhat more model-specific.

\section{Experiment Preparation}

\subsection{Experimental Design}
This experiment can be divided into three parts: generating synthetic datasets (with different levels of noise), training the model using machine learning algorithms, and generating model interpretations using SHAP.

Noise can be divided into class noise and attribute noise \cite{Zhu2004}. 
Class noise is the misclassification or absence of labels.
Attribute noise, on the other hand, are outliers of input attributes.
As the SHAP method calculates the contribution of each attribute to the prediction.
In this project, attribute noise will be added to the dataset during the synthetic data generation stage.

\subsection{Datasets Selection}
Several machine learning benchmark datasets will be used as the original datasets in the experiments. 
And then, different proportions of noise will be added to the datasets to obtain datasets containing different noise levels.
The mushroom classification dataset\cite{misc_mushroom_73} from the UC Irvine(UCI) Machine Learning Repository and the Stellar classification dataset\cite{Fedesoriano_2022} from the Kaggle competition were selected.
\subsubsection{Mushroom Classification Dataset}
The dataset contains 8124 samples and 22 variables (odour, shape, taste, etc. of different parts of the mushroom)\cite{misc_mushroom_73}.
Predict whether a mushroom is poisonous or not based on various attributes.
It is important to note that the attribute values in this dataset are all categorical attributes. 
This means that these attributes have a fixed range of values and noise is added according to the range of values of the attributes.

\subsubsection{Stellar Classification Dataset}
The dataset consists of data from space observations made by the Sloan Digital Sky Survey (SDSS)\cite{Abdurroâ€™uf_2022}. The dataset includes information about the instruments involved in the observations and spectral information about the stars observed. The dataset classifies stars into three categories, galaxies, quasars, and stars, and contains 17 classification attributes and a column of classification labels.
\subsection{Noise Addition Method}
\subsubsection{Mushroom Classification Dataset}

Since the attributes in the mushroom categorical dataset are all categorical attributes, noise must be generated according to the range of values of each attribute in order not to change the nature of the dataset.
Adding noise to the mushroom dataset uses the method of generating random noise based on the range of values of the attributes and replacing the values in the original dataset.
In this article, when noise is added to a dataset, it is added based on attributes.
The method for adding noise to the mushroom dataset is as follows:

First, the column to which the noise is to be added is identified by passing external parameters.

Then, the global distribution of distinct values is extracted from that column of the original dataset.

Then, based on the global distribution and the noise ratio to be added, the number of distinct noise values to be generated is calculated.

Finally, based on the number of noise values, the number of indexes corresponding to each value is extracted from the original dataset and the data pointed to by the indexes is changed to other values.

Fig \ref{Comparison before and after adding noise} shows the change in the number of different values of the odour attribute in the mushroom classification dataset before and after the addition of 5 percents noise.
Sub-figure \ref{comparisonA} demonstrates the number of different odours before adding noise, while sub-figure \ref{comparisonB} displays the number of odours after adding five percent of noise.
\begin{figure}
    \centering

    \subfigure[Original dataset]{
        \includegraphics[width=0.45\textwidth]{fig2.png}
        \label{comparisonA}
    }
    \hfill
    \subfigure[After noise addition]{
        \includegraphics[width=0.45\textwidth]{fig1.png}
        \label{comparisonB}
    }


    \caption{Comparison before and after adding noise}
    \label{Comparison before and after adding noise}
\end{figure}

The proportion of each odor before and after adding noise remained almost unchanged, as shown in Figure \ref{Comparison before and after adding noise}, although there were some minor changes in the number of each odor.

\subsubsection{Stellar Classification Dataset}
In a stellar categorical dataset, all data is numeric, which means that all attributes in the dataset are continuous attributes. Adding noise to continuous attributes is much simpler than adding noise to categorical attributes, where noise can be generated based on various mathematical distributions and added directly to the dataset.
Common types of noise include Gaussian noise, Perlin noise, and others.
\paragraph{Gasussian Noise}
Gaussian noise is a frequently-occurring form of random signal noise, which is also referred to as normally distributed noise, or white noise\cite{jain1989fundamentals}. This type of noise is the result of adding multiple independent random variables together, which follow a Gaussian distribution. This distribution is also known as a normal distribution. Gaussian noise is ubiquitous in numerous natural and engineering systems, such as electronic devices, communication systems, image processing, and measurement equipment.

Gaussian distribution has the following characteristics:

Mean: Gaussian noise has a mean of 0, which means it has an expected value of 0.

Variance: the variance determines how much the Gaussian noise spreads around the mean. 
A smaller variance will concentrate the noise near the mean, while a larger variance will result in a wider range of noise.

Symmetry: the Gaussian distribution is symmetrical, with a peak at the mean and a gradual decay to the sides.

The mathematical expression for Gaussian noise is

\begin{equation}
f(X) = \frac{1}{\sqrt{2\pi\sigma^2}}\cdot e^-\frac{(x-\mu)^2}{2\sigma^2}
\end{equation}
where f(x) is the probability density function, $\mu$ is the mean, and $\sigma$ is the standard deviation.
One can vary the standard deviation of the Gaussian distribution in practice to achieve various levels of Gaussian noise.

Because Gaussian noise follows a Gaussian distribution, most noise values are clustered near the mean, and noise values far from the mean are less likely to occur. This makes Gaussian noise very useful statistically

\paragraph{Perlin Noise}
Perlin noise is an algorithm created by Ken Perlin in 1985 to generate continuous, smooth, pseudo-random noise\cite{perlin1985image}. It is commonly used in computer graphics, animation, and game development to create natural, realistic-feeling textures, terrain, clouds, water waves, and other effects\cite{green2005implementing}.

Perlin noise is known for its ability to generate continuous noise values with smooth transitions in space, without the presence of noticeable edges or abrupt changes. This property makes it exceptionally useful in simulating natural environments and generating textures\cite{perlin1985image}.

Perlin noise generation is achieved through interpolation. This method combines multiple random gradient vectors with the input point positions to obtain a continuous noise value\cite{green2005implementing}. 

The Perlin noise algorithm can be broken down into the following steps:

Create a grid for the input points and determine the stochastic gradient vector for each grid point.
Map the input points to the grid and calculate the offset from each input point to the nearest grid point.
At each grid point, the noise value is calculated by using the offset and the stochastic gradient vector.
The noise values at various grid points are interpolated to produce the final Perlin noise value.\cite{green2005implementing}

There are five parameters in the Python noise library that can be used to control the different Perlin noises generated:

Scale: The scale is a factor used to control the coarseness of the noise texture. Lower values will generate finer textures, and higher values will produce coarser ones.

Octaves: Octaves refer to the number of frequencies used to superimpose the noise textures. Adding more octaves increases detail and complexity, but could also raise the computational demand.

Persistence: Persistence controls how much each frequency contributes to the noise texture. The values range from 0 to 1, where higher values indicate a stronger effect of high-frequency noise on the final outcome.

Lacunarity: The separation parameter, is used to regulate the distance between successive frequencies. It impacts the extent of each frequency.

Seed: The seed value determines the beginning of the noise generation process. Using the same seed value will result in the same noise pattern, facilitating production of a specific noise texture.

\section{Model Training Technology}

This paper used both decision tree and gradient boosting tree models in its experiments. HalvingGridSearchCV (HSGCV) was used to parameterize the model, and the process of HSGCV was evaluated using nested cross-validation in the experiments.

\newpage

\bibliographystyle{splncs04}

\bibliography{ref}

\end{document}